Основные блоки архитектуры:

Character Encoder (разбивка такста на кодпойнты, формирование матрицы с флажками)
Convolutional  Layers -- прочитать про CLCNN в (Deep Learning Book) и (Zhang et al. 2017. Character-level
convolutional networks for text classification.)
Language Encoder (фичи берутся из convolutional layer, 2 fully connected ReLU leayers of size 1024,
  softmax по языкам; его отдельно обучать, потом включать в обучение/инференс в замороженном виде???)
Feature Mixing

Оптимизация под два функционала (Multi-task learning):
  1. country cross entropy - standard softmax cross entropy loss
  2. mixture of von Mises-Fisher distributions (похоже на prior для плотности населения на Земле, но модифицируется
  под твиты в процессе обучения)

Обучение
  * Adam optimizer, lr=0.0005, batch_size=600 (по 100 твитов на GPU, у них их было 6)
  * online performance evaluation, i.e. only a single pass over the dataset, no train/test splits
  * есть ли регуляризация?



Прочитать
  * про temporal convolution for textual data (Deep Learning Book)
  * про CLCNN (Zhang et al. 2017. Character-level convolutional networks for text classification.)
  * про multitask learning: Yu Zhang and Qiang Yang. 2017. A survey on multitask learning (arXiv:1707.08114)
  * про von Mises-Fisher distribution (Izbicki et al., 2019. Exploiting the Earth's Spherical Geometry to Geolocate Images)
  * online learning (Shalev-Schwartz and Ben-David, 2014. Understanding Machine Learning), https://en.wikipedia.org/wiki/Online_machine_learning
    или что-нибудь ещё


EDA про датасет из задания (по Южной Америке)
  * Сколько твитов с размеченным языком (pie chart), какое распределение твитов по языкам (гистограмма)
  * Есть ли вообще азиатские языки и "multibyte-языки" (нужно ли париться с реализацией нескольких строк на символ в character encoder?)
  * Построить распределение по координатам (желательно наложить плотность на карту); проверить, как оно бьется с
    данными о плотности населения (аномалии могут быть интересны)
  * Что известно про авторов твитов, можно ли их определить (сейчас разбито по координатам, но это не обязательно один и тот же автор;
    у одного автора могут быть предпочтительные локации, которые можно обнаружить)
  * Есть ли время публикации и можно ли привязать его к световому дню и, соответственно, добавить prior к определению координат
    (предположительно, есть часы максимальной активности в определенных локациях, коррелирующие со световым днем и размером населенного
    пункта; например, в маленьких населенных пунктах раньше ложатся спать, в больших городах ночная жизнь.)
  * за какой период собраны твиты
  * насколько равномерно в целом распределены твиты по времени?
  * Есть ли заметная миграция населения в какие-то даты (например, праздники, выходные, в т.ч. локальные/страновые)?
    Если есть, можно ли определить места повышенной плотности с привязкой к датам/времени?
  * поле source, судя по всему, даёт упрощенное наименование клиента (Android, iPhone). Какие клиенты в целом указаны в данных? В каких
    пропорциях?

Data augmentation и data leakage
  * можно восстановить авторство по followers_count, following_count, tweet_count как счетчик? (это характеристика автора, а не твита),
    также можно попробовать восстановить граф связности
  * есть conversation_id и in_reply_to_user_id, можно попробовать восстановить цепочку (возможно, с пропусками) и использовать для построения
    графа связности
  * можно ли понять, каким twitter api клиентом делался сбор данных? когда он делался?
  * понять значение всех полей в датасете (м/б это стандартные поля Twitter API? или стандартные наименования полей какого-то
    распространенного клиента -- загуглить по названиям полей); м/б есть описание в одном из других Inca Challanges
  * Можно ли связать распространенность айфонов с благосостоянием и, как следствие, с определенными городами и информацией
    об уровне доходов по городам/странам?
